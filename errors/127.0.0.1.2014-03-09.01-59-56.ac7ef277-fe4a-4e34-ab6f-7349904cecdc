(dp1
S'output'
p2
S'<type \'exceptions.TypeError\'> can only concatenate list (not "str") to list'
p3
sS'layer'
p4
S'/home/hduser/web2py/applications/Hadoop/controllers/default.py'
p5
sS'code'
p6
S'# coding: utf8\n# try something like\nimport os\nimport subprocess\nimport MySQLdb\nTable = "workflow";\nmachine="localhost";\ndatabase_name="hadoop";\ndb_username="root";\npassword="hadoop";\n\ndef index():\n#    return dict(a=1);\n    redirect(URL(\'all_jobs\'));\n\n    return dict(message="hello from default.py")\ndef compile1():\n    return dict(hello="hello");\ntkns=[]\ncodegen1="";\ndef codegen(str="",table=""):\n    posvars=request.post_vars;\n#    //codegen:          generate import-export code without performing actual import/export, modify the gnerated java file, compile it to jar, give it to sqoop.\n#    global $TABLE,$machine,$password,$db_username,$database_name;\n    global codegen1;\n    if str=="":\n       # os.remove(Table+".java");\n       # os.remove(Table+".jar");\n       # os.remove(Table+".class")\n\n        codegen1= "/home/hduser/sqoop/bin/sqoop codegen --connect jdbc:mysql://"+machine+"/"+database_name+" --username "+db_username+" --password \'"+password+"\' --table "+Table ;\n        if posvars[\'op\']=="import":\n            if posvars[\'field_delim\']!="":\n                codegen1=codegen1+" --fields-terminated-by "+"\'" +posvars[\'field_delim\']+"\'";\n            if posvars[\'line_delim\']!="":\n                codegen1=codegen1+" --lines-terminated-by "+"\'" +posvars[\'line_delim\']+"\'";\n            if \'enclosed\' in posvars:\n                if posvars[\'enclosingchar\']==\'"\':\n                    posvars[\'enclosingchar\']=\'\\"\';\n                    codegen1=codegen1+" "+posvars[\'enclosed\']+" \'"+posvars[\'enclosingchar\']+ "\'";\n\n    else:\n        os.remove(TABLE+".java");\n        os.remove(TABLE+".jar");\n        os.remove(TABLE+".class");\n        codegen1=str;\n\n    codegen1 = codegen1+" --bindir . 2> err ; echo $?";\n\n#    echo "codegen command=".$codegen."<br/>";\n    output = os.popen(codegen1).read()\n#    $output= shell_exec($codegen);\n    tkns=output.split(\'\\n\');\n\n #   if output[output.__len__()-2]!="0":\n    return dict (tkns=tkns,message = "codegen wright")\n#       return "<br>??????????????Codegen error<br>";#echo $output;exit(0);\n\n\ndef all_jobs():\n    jobs=[];\n    output = os.popen(""" jps | grep Jps | awk \'{print $1;}\' """).read()\n    output = output.split(\'\\n\')[:-1];\n    try :\n        connection = MySQLdb.connect(host=\'localhost\',user=\'root\', passwd=\'hadoop\', db=database_name)\n        cur=connection.cursor();\n        query = "select * from all_databases where result = 0 AND job_status = 1";\n        cur.execute(query)\n        tables = cur.fetchall()\n        cur1 = connection.cursor();\n        query = "select * from all_databases where job_status = 0";\n        cur1.execute(query)\n        tables2 = cur1.fetchall()\n        cur2 = connection.cursor();\n        query = "select * from all_databases where result != 0";\n        cur2.execute(query)\n        tables3 = cur2.fetchall()\n#        max_id = tables[0][0];\n    except:\n        print "weee2"\n    return dict(L = tables,running = tables2,failed=tables3,db_type="sql");\n\ndef sql1():\n    tables = [];\n    path = \'/\'\n    if \'path\' in request.get_vars:\n        path = request.get_vars[\'path\'];\n    a = "hadoop fs -ls "+path+" | tr -s \' \' | cut -d \' \' -f8"\n    output = os.popen(a).read()\n    tokens = output.split(\'\\n\')\n    error = ""\n    try :\n        connection = MySQLdb.connect(host=\'localhost\',user=\'root\', passwd=\'hadoop\', db=database_name)\n        cur=connection.cursor()\n        query = "show tables"\n        cur.execute(query)\n        tables = cur.fetchall()\n        return dict(tokens=tokens,error=error,tables=tables,test = request.get_vars)\n    except:\n        print "weee"\n        error = "failed to connect to MySQL: "\n        return dict(tokens=tokens,error=error,tables=tables)\n\ndef hdfs1():\n    tables = [];\n    path = \'/\'\n    if \'path\' in request.get_vars:\n        path = request.get_vars[\'path\'];\n    a = "hadoop fs -ls "+path+" | tr -s \' \' | cut -d \' \' -f8"\n    output = os.popen(a).read()\n    tokens = output.split(\'\\n\')\n    error = ""\n    try :\n        connection = MySQLdb.connect(host=\'localhost\',user=\'root\', passwd=\'hadoop\', db=database_name)\n        cur=connection.cursor()\n        query = "show tables"\n        cur.execute(query)\n        tables = cur.fetchall()\n        return dict(tokens=tokens,error=error,tables=tables,test = request.get_vars)\n    except:\n        print "weee"\n        error = "failed to connect to MySQL: "\n        return dict(tokens=tokens,error=error,tables=tables)\n\ndef main():\n    if request.get_vars[\'dbtype\'] == "sql":\n        redirect(URL(\'sql1\'));\n    elif request.get_vars[\'dbtype\'] == "hdfs":\n        redirect(URL(\'hdfs1\'));\n\ndef hdfs():\n    #this is export\n    present_pid = os.getpid();\n    global codegen1;\n    posvars = request.post_vars;\n    posvars[\'op\'] = "export";\n    comm = "sqoop "+posvars[\'op\'];\n\n    max_id = 0;\n    try :\n        connection = MySQLdb.connect(host=\'localhost\',user=\'root\', passwd=\'hadoop\', db=database_name)\n        cur=connection.cursor();\n        query = "insert into all_databases(operation,table_transfered,start_time,job_status) values (\'" + posvars[\'op\'] + "\'," + "\'" + posvars[\'table\'] +"\'," + "NOW(),0);";\n        print query;\n        cur.execute(query)\n        connection.commit();\n        cur1=connection.cursor();\n        query = """ select max(id) from all_databases;  """;\n        cur1.execute(query)\n        tables = cur1.fetchall()\n        max_id = tables[0][0];\n    except:\n        print "weee2"\n        \n    if posvars[\'op\'] == "export":\n        comm=comm + " --connect jdbc:mysql://"+machine+"/"+database_name+" --username "+db_username+" --password \'"+password+"\' --table "+posvars[\'table\']+" "\n        \n        if \'directory\' in posvars:\n            comm=comm+" --export-dir "+posvars[\'directory\'];\n            \n        if \'update\' in posvars:\n            if posvars[\'refcol\']=="":\n                print "Specify the reference column<br/>";\n                exit(0);\n            comm=comm+" --update-key "+posvars[\'refcol\'];\n\n#        comm=comm+" ; echo $?";\n        print "Export command="+comm+"<br>";\n                       ####this is the main execute step .... not done because sqoop not working properly\n\n        comm = comm+ """ ;mysql --user=root --password=hadoop -e "use hadoop;update all_databases set result=$?,job_status=1  where id= """+ str(max_id) +""" AND job_status=0 "; exit 1 """;\n        file1 = open(str(present_pid),\'w\');\n        file1.write(comm);\n        file1.close();\n        pid = os.fork();\n        if pid != 0:\n                try :\n                        connection = MySQLdb.connect(host=\'localhost\',user=\'root\', passwd=\'hadoop\', db=\'hadoop\')\n                        cur=connection.cursor();\n                        query = "update all_databases set pid="+ str(pid+1) + " where id="+str(max_id)+";";\n                        cur.execute(query)\n                        connection.commit();\n                        tables = cur.fetchall()\n                except:\n                        print "weee1"\n\n        else:\n                os.execlp(\'bash\',\'bash\',str(present_pid));\n\n    val=\'0\';#output[output.__len__()-2];\n    redirect(URL(\'all_jobs\'))\n\n\n\ndef sql():\n    print "came to sql"\n    #this is import\n    present_pid = os.getpid();\n    global codegen1;\n    posvars = request.post_vars;\n    posvars[\'op\'] = "import";\n    all_tables = posvars[\'table\'];\n    print posvars;\n    print type(all_tables);\n#    if type(all_tables)==type("str"):\n  #      all_tables=[all_tables];\n    first_flag = 0;\n    print all_tables + "     alllllllllllllllllllllllll"\n    for tab in all_tables:\n        print tab + "        yiyiuyiuy iuyiuyui"\n        comm = "sleep "+ str(first_flag) +" ;sqoop "+posvars[\'op\']+" ";\n        first_flag = first_flag+2;\n        posvars[\'table\'] = tab;\n        max_id = 0;\n        print "before"\n        print posvars[\'table\'];\n        try :\n            print "try came"\n            print posvars[\'table\'];\n            connection = MySQLdb.connect(host=\'localhost\',user=\'root\', passwd=\'hadoop\', db=\'hadoop\')\n            cur=connection.cursor();\n            print "rang",\n            query = "insert into all_databases(operation,table_transfered,start_time,job_status) values (" +"""\'""" + posvars[\'op\'] + """\', """ + "\'" + posvars[\'table\'] +"\'" + ", NOW(),0);";\n            #query = "insert into all_databases(operation,table_transfered,start_time,job_status) values (\'" + posvars[\'op\'] + "\'," + "\'" + posvars[\'table\'] +"\'," + "NOW(),0);";\n            print query;\n            print "anath"\n            cur.execute(query)\n            connection.commit();\n            cur1=connection.cursor();\n            query = """ select max(id) from all_databases;  """;\n            cur1.execute(query)\n            tables = cur1.fetchall()\n            max_id = tables[0][0];\n        except:\n            print "weee2"\n    \n        if posvars[\'op\'] == "import":\n            imp="";\n            if \'encrypt\' in posvars:\n                codegen();\n                array=posvars[\'encrypt_columns\'].split(\',\');#explode(",",$_POST[\'encrypt_columns\']);\n                #print_r($array);\n    #            change_import($TABLE.".java",$array,$_POST[\'enckey\']);\n                compile1();\n                imp="  --jar-file "+Table+".jar --class-name "+Table;\n            print "ranganath likes kovida"\n            comm=comm + " --connect jdbc:mysql://"+machine+"/"+database_name+" --username "+db_username+" --password \'"+password+"\' --append --table "+posvars[\'table\']+" "+imp;\n    \n            if posvars[\'targetdir\']==\'default\':\n                comm=comm+" --target-dir /"+posvars[\'table\'];\n            elif posvars[\'targetdir\']!="":\n                comm=comm+" --target-dir "+posvars[\'targetdir\'];\n    \n    \n            if \'filetype\' in posvars:\n                comm=comm+ " "+posvars[\'filetype\'];\n    \n            comm = comm+ """ ;mysql --user=root --password=hadoop -e "use hadoop;update all_databases set result=$?,job_status=1  where id= """+ str(max_id) +""" AND job_status=0 "; exit 1 """;\n            file1 = open(str(present_pid),\'w\');\n            file1.write(comm);\n            file1.close();\n            print present_pid;\n            pid = os.fork();\n            if pid != 0:\n                    print pid;\n                    try :\n                            connection = MySQLdb.connect(host=\'localhost\',user=\'root\', passwd=\'hadoop\', db=\'hadoop\')\n                            cur=connection.cursor();\n                            query = "update all_databases set pid="+ str(pid+1) + " where id="+str(max_id)+";";\n                            cur.execute(query)\n                            connection.commit();\n                            tables = cur.fetchall()\n                    except:\n                            print "weee1"\n    \n            else:\n                    os.execlp(\'bash\',\'bash\',str(present_pid));\n\n    val=\'0\';#output[output.__len__()-2];\n    redirect(URL(\'all_jobs\'))\n#    return dict(posvars = request.post_vars);\n\nresponse._vars=response._caller(sql)\n'
p7
sS'snapshot'
p8
(dp9
sS'traceback'
p10
S'Traceback (most recent call last):\n  File "/home/hduser/web2py/gluon/restricted.py", line 217, in restricted\n    exec ccode in environment\n  File "/home/hduser/web2py/applications/Hadoop/controllers/default.py", line 283, in <module>\n  File "/home/hduser/web2py/gluon/globals.py", line 372, in <lambda>\n    self._caller = lambda f: f()\n  File "/home/hduser/web2py/applications/Hadoop/controllers/default.py", line 208, in sql\n    print all_tables + "     alllllllllllllllllllllllll"\nTypeError: can only concatenate list (not "str") to list\n'
p11
s.